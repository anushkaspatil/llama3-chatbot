# Llama-3 chatbot on local system using Olama

Welcome to the Llama-3 Chatbot project! This chatbot allows you to interact with the Llama-3 model via a simple command-line interface. Type your messages, and receive responses from Llama-3.

## Table of Contents

- [Installation](#installation)
- [Usage](#usage)
- [Example](#example)
- [Contributing](#contributing)
- [License](#license)

## Installation

### Prerequisites

- Python 3.6 or higher
- `ollama` library

### Steps

1. Clone the repository:
    ```sh
    git clone https://github.com/your-username/llama3-chatbot.git
    cd llama3-chatbot
    ```

2. Create a virtual environment (optional but recommended):
    ```sh
    python -m venv venv
    source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
    ```

3. Install the required Python packages:
    ```sh
    pip install ollama
    ```

## Usage

To start the chat with Llama-3, run the following command:

```sh
python chatbot.py
